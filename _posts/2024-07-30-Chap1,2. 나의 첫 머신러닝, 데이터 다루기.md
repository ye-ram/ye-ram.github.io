---
layout: post
title:  "Chap1,2. 나의 첫 머신러닝, 데이터 다루기"
date:   2024-07-30
categories: Machine Learning
---

## Chap 1-3. 마켓과 머신러닝

> 머신러닝은 누구도 알려주지 않는 기준을 찾아서 일을 한다. 

머신러닝 패키지 **사이킷런**을 사용하기 위해서는 리스트를 세로 방향으로 늘어뜨린 **2차원 리스트**로 만들어야 한다.
```python
fish_data = [[l, w] for l, w in zip(length, weight)]
print(fish_data)
```

**훈련**: 머신러닝 알고리즘이 데이터에서 규칙을 찾는 과정. 사이킷런에서는 fit( ) 메서드가 훈련 담당

**평가**: 훈련된 데이터를 평가하는 과정. 사이킷런에서는 score( ) 메서드로 사용

**KNN(K-Nearest Neighbor)알고리즘**: 주어진 데이터 포인트의 클래스를 예측하기 위해 가장 가까운 K개의 이웃 데이터를 참고하는 분류 및 회귀 알고리즘.  k의 기본값은 5

```python
from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier()
kn.fit(fish_data, fish_target)
kn.score(fish_data, fish_target)

kn.predict([[30, 600]]) # (30, 600) 새로운 데이터의 예측값 출력. 2차원 리스트로 전달해야 하기 때문에 [[  ]]로 데이터를 감싼다. 
# array([1])
```
```python
kn._fit_X # 모델에 전달한 train_data가 있음
kn._y # train_target이 있음

n_neighbors # 참고할 이웃 데이터의 수 결정
p # 거리를 재는 방법 지정. 1은 맨해튼 거리, 2는 유클리디안 거리
n_jobs # 사용할 CPU 코어 지정. -1은 모든 CPU 코어 사용. 1은 기본값
```


## Chap 2-1. 훈련 세트와 테스트 세트

> Q. 전체 데이터를 훈련 세트와 테스트 세트로 나누는 이유는 무엇일까?
> 
> A. 시험 문제와 정답을 알려주고 시험을 치르지 않듯이 머신러닝도 훈련 세트로 훈련을 한 뒤 테스트 세트로 머신러닝 모델의 성능을 평가한다. 

* 지도 학습

  입력 데이터와 해당하는 정답을 사용하여 모델을 학습하는 방식. 즉, 훈련 데이터에 정답이 주어지며, 모델은 이 데이터를 기반으로 학습하여 새로운 데이터에 대한 예측을 수행한다.
  
* 비지도 학습
  
  입력 데이터만 주어지고, 정답이 없는 상태에서 모델이 데이터의 패턴이나 구조를 스스로 학습하는 방식. 즉, 데이터의 레이블이 없으며, 유사한 데이터끼리 그룹화하거나 차원 축소 등의 작업을 수행한다.
  
* 샘플링 편향
  
  훈련 세트와 테스트 세트에 샘플이 섞여 있지 않아 샘플링이 한 쪽으로 치우치는 현상
  
* numpy
  
  seed( ) 난수를 생성하기 위해 정수 초깃값 지정. 초깃값이 같으면 동일한 난수 출력 가능
  
  ```python
  np.random.seed(42)
  ```
  arrange( ) 일정한 간격의 정수 또는 실수 배열을 만듦. 기본 간격은 1
  ```python
  print(np.arrange(3)) # [0, 1, 2]
  print(np.arrange(1, 3)) # [1, 2, 3]   np.arrange(시작숫자, 종료숫자)
  print(np.arrange(1, 2, 0.2)) # [1., 1.2, 1.4, 1.6, 1.8]   np.arrange(시작숫자, 종료숫자, 간격)
  ```


## Chap 2-2. 데이터 전처리

* numpy

  np.column_stack( ) 전달 받은 리스트를 일렬로 세워 나란히 연결

  np.ones( ), np.zeros( ) 원하는 개수의 1과 0을 채운 배열 만듦
  
* train-test 분할

  ```python
  from sklearn.model_selection import train_test_split

  train_input, test_input, train_target, test_target = train_test_split(
		fish_data, fish_target, stratify=fish_target, random_state=42)
  ```

  stratify: 훈련 데이터와 테스트 데이터 모두에서 각 클래스의 비율이 원본 데이터와 유사하게 유지된다. 예를 들어,     원본 데이터 클래스가 A:B = 7:3 의 비율이라면, 훈련 데이터와 테스트 데이터에서도 이 비율을 유지하도록 분할된      다. → 모델이 모든 클래스 학습 가능 → 평가 시 성능이 더 신뢰 가능 →.클래스 불균형 문제를 완화하는 데 도움

* 스케일이 다른 특성 처리 방법

  ![image](https://github.com/user-attachments/assets/95079279-e811-4840-ae28-8ea83f943793)

위 그래프의 데이터처럼 특성의 스케일이 다른 경우 대부분의 머신러닝 알고리즘이 잘 작동하지 않는다. 

1. 표준점수(standard score)

   각 특성값이 평균에서 표준편차의 몇 배만큼 떨어져 있는지를 나타낸다. 

   값에서 평균을 빼고 표준편차를 나누어 계산한다.

   !주의!  훈련 세트를 변환한 방식 그대로 테스트 세트를 변환해야 한다.
   
  ```python
plt.xlim((0, 1000)) # x 축의 범위를 0~1000으로 맞추는 함수. y축은 plt.ylim()
  ```
