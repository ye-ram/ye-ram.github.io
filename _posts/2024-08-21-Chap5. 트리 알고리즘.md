---
layout: post
title:  "Chap5. 트리 알고리즘"
date:   2024-08-21
categories: Machine Learning
---

## Chapter 5-1: 결정 트리

결정 트리는 데이터 전처리를 할 필요가 없다는 엄청난 장점을 가진다. 결정 과정을 이해하기 쉽기 때문에 제 3자에게 설명하기도 쉽다. 

![image](https://github.com/user-attachments/assets/ee67f7f9-cf95-47af-ae21-3ec54d5c8224)

1. **지니 불순도 Gini Impurity**

   **노드에서 데이터를 분할할 기준**으로 DecisionTreeClassifier 클래스의 criterion 매개변수의 기본값이다.

   ![image](https://github.com/user-attachments/assets/ad8e3842-6113-449e-adbe-9f74cf763413)

   결정 트리 모델은 **부모 노드와 자식 노드의 불순도 차이가 가장 크게 되도록** 트리를 분할시킨다. 즉, **informaton gain이 최대가 되도록** 데이터를 분할한다. 

2. **가지치기**

   결정 트리의 점수가 과대적합되어 보인다면 트리가 너무 깊지는 않은지 확인해 보아야 한다. max_depth를 통해 트리의 깊이를 지정할 수 있다.

   ```python
   dt = DecisionTreeClassifier(random_state=42, max_depth=3)
  ```

   특성 중요도를 통해 ‘sugar’ 당도가 가장 중요한 특성임을 알 수 있다.
  ```python
  print(dt.feature_importances_)
  [0.12345626 0.86862934 0.0079144 ]
  ```


## Chapter 5-2: 교차 검증과 그리드 서치

* 검증 세트

  훈련 세트 : 검증 세트 : 테스트 세트 = 6 : 2 : 2

  **훈련 세트**로 모델을 훈련하고 **검증 세트**로 모델을 평가한다. 테스트 해보고 싶은 매개변수를 모두 평가해본 뒤 가장 좋은 성능을 보인 모델을 **테스트 세트**로 최종 평가한다.

  ```python
    # 훈련 세트, 검증 세트, 테스트 세트로 나누는 방법
   from sklearn.model_selection import train_test_split
   train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state = 42)
  sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state = 42)
  ```

* k-폴드 교차 검증

  기존의 훈련 세트를 훈련 세트와 검증 세트로 나누어서 훈련에 필요한 데이터의 수가 부족해지는 문제가 발생하기도 한다.

  적은 데이터 수로도 안정적인 검증 점수를 얻기 위해서 교차 검증을 사용한다.

  ![image](https://github.com/user-attachments/assets/7af6a14a-6235-489f-84fa-51dd7801c156)

  cross_validate( ) 함수는 기본적으로 5개로 훈련 세트를 나누어서 교차 검증을 수행한다.

  ```python
  from sklearn.model_selection import cross_validate
  scores = cross_validate(dt, train_input, train_target)
  print(scores)
  
  {'fit_time': array([0.0125494 , 0.00740671, 0.00760531, 0.0075438 , 0.00715327]), 
  'score_time': array([0.00130272, 0.00112629, 0.00111675, 0.00112343, 0.0011127 ]), 
  'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}
  
  # fit_time은 훈련하는 시간, score_time은 검증하는 시간을 의미한다. 
  ```
  위 코드에서 test_score은 5개의 검증 점수이기 때문에 5개의 점수를 평균해서 최종 검증 점수를 출력한다.
  
  ```python
  import numpy as np
  print(np.mean(scores['test_score']))
  ```

  cross_validate( ) 함수는 훈련 세트를 섞어서 폴드를 나누지 않기 때문에 훈련 세트를 섞기 위해서는 분할기(splitter)를 정해야 한다. 기본적으론 K-fold 교차 검증을 사용한다.
  
  ```python
  from sklearn.model_selection import cross_validate
  from sklearn.model_selection import StratifiedKFold
  splitter = StratifiedKFold(n_splits = 10, shuffle=True, random_state=42)
  scores = cross_validate(dt, train_input, train_target, cv=splitter)
  print(np.mean(scores['test_score']))
  ```
  회귀 모델: K-Fold  / 분류 모델: StratifiedKFold

* 하이퍼 파라미터 튜닝

  모델에게 가장 적합한 하이퍼 파라미터 찾기

  *하이퍼 파라미터: 모델을 생성할 때 사용자가 직접 설정하는 변수 *

  1. **그리드 서치 Grid Search**

     내가 설정한 범위 안에서의 최적 파라미터를 찾는다. 모든 경우에서의 최적 파라미터라고 볼 수 없다! 더 나은 결과를 내는 파라미터가 존재할 수도 있고 안 할 수도 있다는 말!

     GridSearhCV 클래스는 하이퍼 파라미터 탐색과 교차 검증을 한 번에 수행한다.

     ```python
     from sklearn.model_selection import GridSearchCV
     params = {'min_impurity_decrease':np.arange(0.0001, 0.001, 0.0001),
               'max_depth' : range(5, 20, 1),
               'min_samples_split': range(2, 100, 10)
               }
     # np.arange( )는 정수, 소수 둘 다 사용 가능하고 range( )는 정수에만 사용 가능하다.
    
     gs = GridSearchCV(DecisionTreeClassifier(random_state = 42), params, n_jobs=-1)
     gs.fit(train_input, train_target)
     print(gs.best_params_) # 최상의 파라미터 출력
     print(gs.cv_results_['mean_test_score']) # 각 매개변수의 검증점수 평균
    
     np.argmax( )는 배열에서 가장 큰 값의 인덱스를 반환하고 np.max( )는 배열에서 가장 큰 값을 반환한다. 
     ```

  2. **랜덤 서치 Random Search**

     그리드 서치보다 훨씬 교차 검증 수를 줄이면서 넓은 영역을 효과적으로 탐색할 수 있다. 그리드 서치에서는 하이퍼 파라미터 값의 목록을 전달했지만 랜덤 서치에서는 하이퍼 파라미터가 될 수 있는 값의 확률 분포를 전달하기 때문이다.

     ```python
     from scipy.stats import uniform, randint
     params = {'min_impurity_decrease' : uniform(0.0001, 0.001),
               'max_depth' : randint(20, 50),
               'min_samples_split': randint(2, 25),
               'min_samples_leaf' : randint(1, 25)
               }
     from sklearn.model_selection import RandomizedSearchCV
     gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42, splitter='random'), params, n_iter=100, n_jobs=-1, random_state=42)
     gs.fit(train_input, train_target)
     ```




