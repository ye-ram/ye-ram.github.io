---
layout: post
title:  "Chap3. 회귀 알고리즘과 모델 규제"
date:   2024-08-05
categories: Machine Learning
---

## Chapter 3-1. k-최근접 이웃 회귀

1. **k-최근접 이웃 회귀**

   예측하려는 샘플에 가장 가까운 k개의 샘플을 고른다. k개의 샘플의 평균 값 = 샘플의 예측값

   * reshape(): 사이킷런에 사용할 train data는 2차원 배열이어야 한다. reshape()은 배열의 크기를 바꿔준다.
   
     ```python
     train_input = train_input.shape(-1, 1)
     test_input = test_input.shape(-1, 1)
     ```

2. 훈련시킨 모델의 평가

   회귀의 경우 밑의 두 가지 방식으로 모델의 평가를 한다.

   * 결정계수(R^2): 1에 가까울수록 좋다.

     ```python
     knr.score(test.input, test.target)
     ```

   * MAE mean_absolute_error(): |실제값과 예측값의 차| 의 평균

     ```python
     from sklearn.metrics import mean_absolute_error

     test_prediction = knr.predict(test.input)
     mae = mean_absolute_error(test_target, test_prediction)
     print(mae) # 19.1571 
      ```

     MAE가 19라면 예측이 평균적으로 19 정도 실제값과 다르다는 것을 나타낸다.

     ![image](https://github.com/user-attachments/assets/329fa292-fc8f-4bd1-92c2-f0c17f075fe8)

   
3. 과대적합 vs 과소적합

   * 과대적합(over-fitting): 모델이 train data에만 잘 맞는 경우에 발생한다.

     훈련 세트에서는 점수가 굉장히 좋았는데 테스트 세트에서는 점수가 굉장히 안 좋은 경우.

     해결방법: 모델을 덜 복잡하게(k-최근접 이웃은 k값 늘리기)
     
   * 과소적합(underfitting): 모델이 너무 단순해서 훈련 세트에 적절히 훈련되지 않거나 데이터의 크기가 작은 경우에 발생한다.(데이터의 크기가 작으면 테스트 세트가 훈련 세트의 특징을 따르지 못 하는 경우도 있다.)

      훈련 세트는 점수가 안 좋지만 테스트 세트의 점수가 좋은 경우. 둘 다 낮은 경우.

      해결방법: 모델을 더 복잡하게(k-최근접 이웃은 k값 줄이기)
     
   
